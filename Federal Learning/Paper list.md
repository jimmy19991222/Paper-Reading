# Federated Learning paper list

## None-iid

1. [FEDERATED OPTIMIZATION IN HETEROGENEOUS NETWORKS](https://proceedings.mlsys.org/paper/2020/file/38af86134b65d0f10fe33d30dd76442e-Paper.pdf) (FedProx, SysML 2020, CMU, cited by 858)

   directly limits the local updates by â„“2-norm distance

   

2. [SCAFFOLD: Stochastic Controlled Averaging for Federated Learning](https://arxiv.org/pdf/1910.06378.pdf) (SCAFFOLD, ICML 2020, EPFL, cited by 382)

   corrects the local updates via variance reduction

3. [FedProc-Prototypical Contrastive Federated Learning on Non-IID data](https://arxiv.org/pdf/2109.12273.pdf) (arxiv 2021.9)

4. [Model-Contrastive Federated Learning](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Model-Contrastive_Federated_Learning_CVPR_2021_paper.pdf) (MOON, CVPR 2021, NUS, cited by 45)

   MOON conduct contrastive learning in model-level. 

   show that FedProx and SCAFFOLD can perform as bad as FedAvg.

5. [Fine-tuning Global Model via Data-Free Knowledge Distillation for Non-IID Federated Learning](https://arxiv.org/pdf/2203.09249.pdf) (arxiv 2022.3)

6. [FedDC- Federated Learning with Non-IID Data via Local Drift Decoupling and Correction](https://arxiv.org/pdf/2203.11751.pdf) (arxiv 2022.3)

7. [Ensemble Distillation for Robust Model Fusion in Federated Learning](https://proceedings.neurips.cc/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Paper.pdf) (FedDF, NeurIPS 2020, EPFL, cited by 125)

8. [Data-Free Knowledge Distillation for Heterogeneous Federated Learning](http://proceedings.mlr.press/v139/zhu21b/zhu21b.pdf) (FedGEN, ICML 2021, Michigan State University, cited by 24)

9. [Federated Robustness Propagation: Sharing Adversarial Robustness in Federated Learning](https://arxiv.org/pdf/2106.10196.pdf) (FedRBN, arxiv 2021.6, Michigan State University, cited by 6)

10. [FedMD: Heterogenous Federated Learning via Model Distillation](https://arxiv.org/pdf/1910.03581.pdf) (NeurIPS 2019 workshop, cited by 161)

11. [Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge](https://proceedings.neurips.cc/paper/2020/file/a1d4c20b182ad7137ab3606f0e3fc8a4-Paper.pdf) (FedGKT, NeurIPS 2020, cited by 72)

12. [Salvaging federated learning by local adaptation](https://arxiv.org/pdf/2002.04758) (arxiv 2020.2, Cornell University, cited by 88)

13. [GEAR: A Margin-based Federated Adversarial Training Approach](https://federated-learning.org/fl-aaai-2022/Papers/FL-AAAI-22_paper_34.pdf) (AAAI 2022 workshop on Trustable, zju)

14. [Ensemble Attention Distillation for Privacy-Preserving Federated Learning](https://openaccess.thecvf.com/content/ICCV2021/papers/Gong_Ensemble_Attention_Distillation_for_Privacy-Preserving_Federated_Learning_ICCV_2021_paper.pdf) (FedAD, ICCV 2021, cited by 5)

15. [FedProto: Federated Prototype Learning across Heterogeneous Clients](https://www.aaai.org/AAAI22Papers/AAAI-6846.YueT.pdf) (FedProto, AAAI 2022, cited by 2)

16. [Federated Learning for Non-IID Data via Unified Feature Learning and Optimization Objective Alignment](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Federated_Learning_for_Non-IID_Data_via_Unified_Feature_Learning_and_ICCV_2021_paper.pdf) (ICCV 2021, pku, cited by 5)

17. [FEDAUX: Leveraging Unlabeled Auxiliary Data in Federated Learning](http://iphome.hhi.de/samek/pdf/SatTNNLS21b.pdf) (FedAUX, *IEEE Transactions on Neural Networks and Learning Systems* 2021, cited by 8)



## Adversarial FL

4. [FAT: Federated Adversarial Training](https://arxiv.org/pdf/2012.01791.pdf) (NeurIPS 2020 Workshop, Imperial College London, cited by 9)
5. [$\alpha$-Weighted Federated Adversarial Training](https://openreview.net/pdf?id=vxlAHR9AyZ6) (ICLR 2022)